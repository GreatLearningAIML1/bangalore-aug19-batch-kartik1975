{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to NN_Project_ Resi_6_Solutions_KK_ver 5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhOo7SvPsf+gWn7FTJrxtb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreatLearningAIML1/bangalore-aug19-batch-kartik1975/blob/master/Introduction_to_NN_Project__Resi_6_Solutions_KK_ver_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0lIhoZoorii",
        "colab_type": "text"
      },
      "source": [
        "Data Description: Given a Bank customer, can we build a classifier that can determine whether they will leave or not using Neural networks?\n",
        "\n",
        "The dataset contains 10,000 sample points with 14 distinct features such as CustomerId, CreditScore, Geography, Gender, Age, Tenure, Balance etc. Know your data: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling\n",
        "\n",
        "Context: Businesses like banks which provide service have to worry about problem of 'Churn' i.e. customers leaving and joining another service provider. It is important to understand which aspects of the service influence a customer's decision in this regard. Management can concentrate efforts on improvement of service, keeping in mind these priorities.\n",
        "\n",
        "1. Steps and Milestones (100%)\n",
        "\n",
        "2. Setup Environment and Load Necessary Packages (5%)\n",
        "\n",
        "3. Data Preparation (40%)\n",
        "\n",
        "4. Loading Data (5%)\n",
        "\n",
        "5. Cleaning Data (10%)\n",
        "\n",
        "6. Data Representation & Feature Engineering (If Any) (15%)\n",
        "\n",
        "7. Creating Train and Validation Set (10%)\n",
        "\n",
        "8. Model Creation (30%)\n",
        "\n",
        "9. Write & Configure Model (10%)\n",
        "\n",
        "10. Compile Model (10%)\n",
        "\n",
        "11. Build Model & Checking Summary (10%)\n",
        "\n",
        "12. Training and Evaluation (25%)\n",
        "\n",
        "13. Run Multiple Experiments (10%)\n",
        "\n",
        "14. Reason & Visualize Model Performance (5%)\n",
        "\n",
        "15. Evaluate Model on Test Set (10%)\n",
        "\n",
        "Learning Outcomes:\n",
        "\n",
        "a. Neural Networks for Predictive Analytics\n",
        "\n",
        "b. Fine-tuning Model\n",
        "\n",
        "c. Data Preparation\n",
        "\n",
        "d. Feature Engineering\n",
        "\n",
        "e. Visualization\n",
        "\n",
        "The points distribution for this case is as follows:\n",
        "\n",
        "* Read the data set\n",
        "\n",
        "* Drop the columns which are unique for all users like IDs (2.5 points)\n",
        "\n",
        "* Distinguish the feature and target set (2.5 points)\n",
        "\n",
        "* Divide the data set into training and test sets ( 2.5 points)\n",
        "\n",
        "* Normalize the train and test data (5 points)\n",
        "\n",
        "* Initialize & build the model (10 points)\n",
        "\n",
        "* Predict the results using 0.5 as a threshold (5 points)\n",
        "\n",
        "* Print the Accuracy score and confusion matrix (2.5 points)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CagYOa9gqhNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "fd432d7d-29e4-4555-cdcd-3e3bd0845dd3"
      },
      "source": [
        "pip install scikit-learn==0.22.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/d0/860c4f6a7027e00acff373d9f5327f4ae3ed5872234b3cbdd7bcb52e5eff/scikit_learn-0.22-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.0) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.0) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.0) (0.14.1)\n",
            "Installing collected packages: scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.1\n",
            "    Uninstalling scikit-learn-0.22.1:\n",
            "      Successfully uninstalled scikit-learn-0.22.1\n",
            "Successfully installed scikit-learn-0.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnjxIQX2sKQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "import os\n",
        "#print(os.listdir(\"../input\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebUV4oehsp3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a6dccde-5fb6-4264-e334-b505ad29c05c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2AX-EDixEju",
        "colab_type": "text"
      },
      "source": [
        "**Read the data set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JQqiawjs6bi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "b2987e1c-cae6-44eb-ac4e-63f699b4b494"
      },
      "source": [
        "#importing the dataset\n",
        "\n",
        "bankdata = pd.read_csv('/content/drive/My Drive/Colab Notebooks/bank.csv', index_col='RowNumber')\n",
        "bankdata.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RowNumber</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           CustomerId   Surname  ...  EstimatedSalary Exited\n",
              "RowNumber                        ...                        \n",
              "1            15634602  Hargrave  ...        101348.88      1\n",
              "2            15647311      Hill  ...        112542.58      0\n",
              "3            15619304      Onio  ...        113931.57      1\n",
              "4            15701354      Boni  ...         93826.63      0\n",
              "5            15737888  Mitchell  ...         79084.10      0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLRK_WH7yXdk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "ecfce822-f54f-463c-bcd2-039f68e8bd3f"
      },
      "source": [
        "bankdata.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 10000 entries, 1 to 10000\n",
            "Data columns (total 13 columns):\n",
            "CustomerId         10000 non-null int64\n",
            "Surname            10000 non-null object\n",
            "CreditScore        10000 non-null int64\n",
            "Geography          10000 non-null object\n",
            "Gender             10000 non-null object\n",
            "Age                10000 non-null int64\n",
            "Tenure             10000 non-null int64\n",
            "Balance            10000 non-null float64\n",
            "NumOfProducts      10000 non-null int64\n",
            "HasCrCard          10000 non-null int64\n",
            "IsActiveMember     10000 non-null int64\n",
            "EstimatedSalary    10000 non-null float64\n",
            "Exited             10000 non-null int64\n",
            "dtypes: float64(2), int64(8), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGuSy-FByeEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "0dc033c4-6daf-4da3-e548-67fa7f726f68"
      },
      "source": [
        "bankdata.describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.569094e+07</td>\n",
              "      <td>650.528800</td>\n",
              "      <td>38.921800</td>\n",
              "      <td>5.012800</td>\n",
              "      <td>76485.889288</td>\n",
              "      <td>1.530200</td>\n",
              "      <td>0.70550</td>\n",
              "      <td>0.515100</td>\n",
              "      <td>100090.239881</td>\n",
              "      <td>0.203700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.193619e+04</td>\n",
              "      <td>96.653299</td>\n",
              "      <td>10.487806</td>\n",
              "      <td>2.892174</td>\n",
              "      <td>62397.405202</td>\n",
              "      <td>0.581654</td>\n",
              "      <td>0.45584</td>\n",
              "      <td>0.499797</td>\n",
              "      <td>57510.492818</td>\n",
              "      <td>0.402769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.556570e+07</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.580000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.562853e+07</td>\n",
              "      <td>584.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51002.110000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.569074e+07</td>\n",
              "      <td>652.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>97198.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100193.915000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.575323e+07</td>\n",
              "      <td>718.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>127644.240000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>149388.247500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.581569e+07</td>\n",
              "      <td>850.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>250898.090000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>199992.480000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         CustomerId   CreditScore  ...  EstimatedSalary        Exited\n",
              "count  1.000000e+04  10000.000000  ...     10000.000000  10000.000000\n",
              "mean   1.569094e+07    650.528800  ...    100090.239881      0.203700\n",
              "std    7.193619e+04     96.653299  ...     57510.492818      0.402769\n",
              "min    1.556570e+07    350.000000  ...        11.580000      0.000000\n",
              "25%    1.562853e+07    584.000000  ...     51002.110000      0.000000\n",
              "50%    1.569074e+07    652.000000  ...    100193.915000      0.000000\n",
              "75%    1.575323e+07    718.000000  ...    149388.247500      0.000000\n",
              "max    1.581569e+07    850.000000  ...    199992.480000      1.000000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK6ZqPzCyu1q",
        "colab_type": "text"
      },
      "source": [
        "High Level Data findings: \n",
        "* Age: between 18-92\n",
        "* Tenure:less then one year to 10 years\n",
        "* CreditScore: This score should should be according to FICO standard, it's between 350-850\n",
        "* Balance: 0 - ~250,000\n",
        "* NumOfProduct: Number of product, it's between 1-4\n",
        "* HasCrdCard:Some people have credit card, some don't\n",
        "* IsActiveMember: Whether an user is active or not\n",
        "* EstimatedSalary: it's between 11 - ~200000, who has 11 as salary？\n",
        "* Exited: 1 - exited, 0 - existed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtKXat3_zPq3",
        "colab_type": "text"
      },
      "source": [
        "**Drop the columns which are unique for all users like IDs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FxeAFWfvhzw",
        "colab_type": "text"
      },
      "source": [
        "Data Prep:\n",
        "\n",
        "* The information about the customer is given in columns 0 to 12 and the desired output is stored in the  last column (13th column) of the dataset. \n",
        "* Customer ID, & Surname need not be considered in classification, hence as a dimentionality reduction conideration we can consider use from columns (CreditScore) 3 through the 13th column for Data Analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCKDkuzdvGer",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "357822f3-371a-4072-b7cf-2f34a65990c6"
      },
      "source": [
        "X_columns = bankdata.columns.tolist()[2:12]\n",
        "y_columns = bankdata.columns.tolist()[-1:]\n",
        "print(f'All columns: {bankdata.columns.tolist()}')\n",
        "print()\n",
        "print(f'X values: {X_columns}')\n",
        "print()\n",
        "print(f'y values: {y_columns}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All columns: ['CustomerId', 'Surname', 'CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']\n",
            "\n",
            "X values: ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
            "\n",
            "y values: ['Exited']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRueXACbwz7e",
        "colab_type": "text"
      },
      "source": [
        "**Distinguishing the feature and target set in the**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJt4X0d6vUkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All columns from Credit Score to Estimated Salary are taken as inputs\n",
        "X = bankdata[X_columns].values \n",
        "# desired output : whether customer exited or not ?\n",
        "y = bankdata[y_columns].values "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeg7TSduzswl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4d910bad-54ad-499d-f418-d13514433b26"
      },
      "source": [
        "bankdata['Geography'].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "France     5014\n",
              "Germany    2509\n",
              "Spain      2477\n",
              "Name: Geography, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0onPVf1z2pq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "bf9d1be5-71ca-4b60-f080-acdfb5b14303"
      },
      "source": [
        "sns.barplot(x='Geography',y='Exited', hue='Gender',data=bankdata)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f93dc240908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEMCAYAAADqG+D0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuEQJREREXPL/AE4oHDE/oYv9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbPKOTrJx-U2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoding categorical (string based) data. Country: there are 3 options: France, Spain and Germany\n",
        "# This will convert those strings into scalar values for analysis\n",
        "#print(X[:8,1], '... will be encoded to: ')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_X_country_encoder = LabelEncoder()\n",
        "X[:,1] = label_X_country_encoder.fit_transform(X[:,1])\n",
        "#print(X[:8,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpOTGlh81NQp",
        "colab_type": "text"
      },
      "source": [
        "Pipeline perform sequence of different transformations (find set of features, generate new features, select only some good features) of raw dataset before applying final estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC54LA2m1PQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    [('Categorizer', ColumnTransformer(\n",
        "         [ # Gender\n",
        "          (\"Gender Label encoder\", OneHotEncoder(categories='auto', drop='first'), [2]),\n",
        "           # Geography\n",
        "          (\"Geography One Hot\", OneHotEncoder(categories='auto', drop='first'), [1])\n",
        "         ], remainder='passthrough', n_jobs=1)),\n",
        "     # Standard Scaler for the classifier\n",
        "    ('Normalizer', StandardScaler())\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK9QZY_U1XSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pipeline.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU_Zjr1u1bN6",
        "colab_type": "text"
      },
      "source": [
        "**Divide the data set into training and test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD35nKS31kgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training and Testing set.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huPqv9Ro1qqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1c6ec78e-638f-464e-c5fd-9a68601934dd"
      },
      "source": [
        "print(f'train shape: {X_train.shape}, {y_train.shape}')\n",
        "print(f'test shape: {X_test.shape}, {y_test.shape}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape: (8000, 11), (8000, 1)\n",
            "test shape: (2000, 11), (2000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gkz7dX52SFy",
        "colab_type": "text"
      },
      "source": [
        "**Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu7-Z2452XDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "127f5e9c-1a75-4c37-903d-d4fc58fb331f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkwIE9hr2pBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9a66c826-4cdf-4b67-e2df-59225bda296f"
      },
      "source": [
        "# Initializing the ANN\n",
        "classifier = Sequential()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbNkEfkO2rUR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "dc5f6010-0173-47bc-ba67-596a0a68cffb"
      },
      "source": [
        "# This adds the input layer (by specifying input dimension) AND the first hidden layer (units)\n",
        "classifier.add(Dense(6, activation = 'relu', input_shape = (X_train.shape[1], )))\n",
        "classifier.add(Dropout(rate=0.1)) "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-4hBHqd25G4",
        "colab_type": "text"
      },
      "source": [
        "The amount of nodes (dimensions) in the hidden layer should be the average of your input and output features, i.e if there are 11 dimensions (representing Independent variables Note: Countries still compose only one dimension) and the expected output is looking for a binary output, then, we calculate this to be  (11+1)÷2=6 .\n",
        "\n",
        "The breakdown of the inputs for the first layer is as follows:\n",
        "\n",
        "*units: *6 nodes (number of nodes in hidden layer)*. number of nodes are in the next layer.\n",
        "\n",
        "*activiation: *relu becasue we are in an input layer*. It uses the ReLu activation function for the layer. This is equivalent to  𝑚𝑎𝑥(0,𝑊×𝑥𝑇+𝑏) \n",
        "\n",
        "*input_dim: *11 because we span 11 dimensions in our input layer*. This is needed for the first added layer. \n",
        "\n",
        "*The subsequent layers's input dimensions can be inferred using the previously added layer's output dimension. The next hidden layer will know what to expect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6pHZLpK3T2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This adds the input layer (by specifying input dimension) AND the first hidden layer (units)\n",
        "classifier.add(Dense(6, activation = 'relu', input_shape = (X_train.shape[1], )))\n",
        "classifier.add(Dropout(rate=0.1)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cMbNui14Aj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the second hidden layer\n",
        "# Notice that we do not need to specify input dim. \n",
        "classifier.add(Dense(6, activation = 'relu')) \n",
        "classifier.add(Dropout(rate=0.1)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4VGZXg64FKc",
        "colab_type": "text"
      },
      "source": [
        "Adding another layer to this model to implement Deep Learning, which is an artificial Neural network with many layers. The second hidden layer also have 6 nodes, just playing with the same arithmetic used to determine the dimensions of the first hidden layer (average of input and output layers)  (11+1)÷2=6 ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77UFVA2p4oQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the output layer\n",
        "# Notice that we do not need to specify input dim. \n",
        "# we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)\n",
        "# We use the sigmoid because we want probability outcomes\n",
        "classifier.add(Dense(1, activation = 'sigmoid')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT8RvoTb4Px-",
        "colab_type": "text"
      },
      "source": [
        "Adding the output layer\n",
        "The breakdown of the inputs for the output layer is as follows:\n",
        "\n",
        "* activiation: sigmoid becasue we are in an output layer. It uses the Sigmoid activation function for  𝜙 . This is used instead of the ReLu function becasue it generates probabilities for the outcome. We want the probability that each customer leaves the bank.\n",
        "\n",
        "* units: 6 nodes (number of nodes in hidden layer). One can think of this as number of nodes are in the next layer.\n",
        "\n",
        "* input_dim: 11 because we span 11 dimensions in our input layer. This is needed for the first added layer. The subsequent layers's input dimensions can be inferred using the previously added layer's output dimension. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-j672nS4OEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0ca63c12-2ebc-47ea-d380-cfa957276e35"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 6)                 72        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 163\n",
            "Trainable params: 163\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heS56ewD49AK",
        "colab_type": "text"
      },
      "source": [
        "If we want more than 2 categories, then change is needed in\n",
        "\n",
        "* the units parameter to match the desired category count\n",
        "\n",
        "* the activation field to softmax - Basically a sigmoid function but applied to a dependent variable that has more than 2 categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wR2qbVk7zY7",
        "colab_type": "text"
      },
      "source": [
        "**Compiling the Neural Network**\n",
        "\n",
        "Basically applying Stochastic Gradient descent on the whole Neural Network. We are Tuning the individual weights on each neuron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CUkQdX_73I3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "15bfc844-5b97-4760-8b7e-34a922bd2fac"
      },
      "source": [
        "classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4usVRt4I8Vrm",
        "colab_type": "text"
      },
      "source": [
        "* optimizer: \"adam\" - algorithm to find the optimal set of weights in the neural networks. An efficeint variation of Stochastic Gradient Descent.\n",
        "\n",
        "* loss: binary_crossentropy- This is the loss function used within \"adam\". This should be the logarthmic loss. If our dependent (output variable) is Binary, it is binary_crossentropy. If Categorical, then it is called categorical_crossentropy\n",
        "\n",
        "* metrics: [accuracy] is the accuracy metrics which will be evaluated(minimized) by the model. This is used as accuracy criteria to improve model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B63qTtPM9MgY",
        "colab_type": "text"
      },
      "source": [
        "**Fitting the Neural Network to our training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCZ9z97k9TjE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1cbeb41d-56d1-4147-e81e-29666165af24"
      },
      "source": [
        "history = classifier.fit(X_train, y_train, batch_size=32, epochs=200, validation_split=0.1, verbose=2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 7200 samples, validate on 800 samples\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 1s - loss: 0.6929 - acc: 0.5964 - val_loss: 0.5337 - val_acc: 0.7937\n",
            "Epoch 2/200\n",
            " - 0s - loss: 0.5115 - acc: 0.7961 - val_loss: 0.4721 - val_acc: 0.7950\n",
            "Epoch 3/200\n",
            " - 0s - loss: 0.4790 - acc: 0.8000 - val_loss: 0.4413 - val_acc: 0.8063\n",
            "Epoch 4/200\n",
            " - 0s - loss: 0.4601 - acc: 0.8078 - val_loss: 0.4159 - val_acc: 0.8187\n",
            "Epoch 5/200\n",
            " - 0s - loss: 0.4422 - acc: 0.8115 - val_loss: 0.3999 - val_acc: 0.8275\n",
            "Epoch 6/200\n",
            " - 0s - loss: 0.4360 - acc: 0.8139 - val_loss: 0.3892 - val_acc: 0.8325\n",
            "Epoch 7/200\n",
            " - 0s - loss: 0.4235 - acc: 0.8235 - val_loss: 0.3790 - val_acc: 0.8425\n",
            "Epoch 8/200\n",
            " - 0s - loss: 0.4179 - acc: 0.8272 - val_loss: 0.3735 - val_acc: 0.8488\n",
            "Epoch 9/200\n",
            " - 0s - loss: 0.4085 - acc: 0.8308 - val_loss: 0.3665 - val_acc: 0.8500\n",
            "Epoch 10/200\n",
            " - 0s - loss: 0.4010 - acc: 0.8332 - val_loss: 0.3606 - val_acc: 0.8525\n",
            "Epoch 11/200\n",
            " - 0s - loss: 0.3978 - acc: 0.8350 - val_loss: 0.3571 - val_acc: 0.8538\n",
            "Epoch 12/200\n",
            " - 0s - loss: 0.3917 - acc: 0.8381 - val_loss: 0.3545 - val_acc: 0.8550\n",
            "Epoch 13/200\n",
            " - 0s - loss: 0.3907 - acc: 0.8358 - val_loss: 0.3554 - val_acc: 0.8538\n",
            "Epoch 14/200\n",
            " - 0s - loss: 0.3887 - acc: 0.8364 - val_loss: 0.3561 - val_acc: 0.8500\n",
            "Epoch 15/200\n",
            " - 0s - loss: 0.3836 - acc: 0.8360 - val_loss: 0.3514 - val_acc: 0.8550\n",
            "Epoch 16/200\n",
            " - 0s - loss: 0.3898 - acc: 0.8360 - val_loss: 0.3522 - val_acc: 0.8512\n",
            "Epoch 17/200\n",
            " - 0s - loss: 0.3862 - acc: 0.8357 - val_loss: 0.3497 - val_acc: 0.8500\n",
            "Epoch 18/200\n",
            " - 0s - loss: 0.3818 - acc: 0.8390 - val_loss: 0.3474 - val_acc: 0.8550\n",
            "Epoch 19/200\n",
            " - 0s - loss: 0.3834 - acc: 0.8365 - val_loss: 0.3475 - val_acc: 0.8538\n",
            "Epoch 20/200\n",
            " - 0s - loss: 0.3804 - acc: 0.8379 - val_loss: 0.3448 - val_acc: 0.8562\n",
            "Epoch 21/200\n",
            " - 0s - loss: 0.3827 - acc: 0.8390 - val_loss: 0.3443 - val_acc: 0.8562\n",
            "Epoch 22/200\n",
            " - 0s - loss: 0.3805 - acc: 0.8393 - val_loss: 0.3418 - val_acc: 0.8612\n",
            "Epoch 23/200\n",
            " - 0s - loss: 0.3777 - acc: 0.8408 - val_loss: 0.3411 - val_acc: 0.8600\n",
            "Epoch 24/200\n",
            " - 0s - loss: 0.3809 - acc: 0.8372 - val_loss: 0.3422 - val_acc: 0.8612\n",
            "Epoch 25/200\n",
            " - 0s - loss: 0.3796 - acc: 0.8406 - val_loss: 0.3399 - val_acc: 0.8625\n",
            "Epoch 26/200\n",
            " - 0s - loss: 0.3818 - acc: 0.8403 - val_loss: 0.3410 - val_acc: 0.8588\n",
            "Epoch 27/200\n",
            " - 0s - loss: 0.3741 - acc: 0.8421 - val_loss: 0.3380 - val_acc: 0.8712\n",
            "Epoch 28/200\n",
            " - 0s - loss: 0.3774 - acc: 0.8431 - val_loss: 0.3382 - val_acc: 0.8650\n",
            "Epoch 29/200\n",
            " - 0s - loss: 0.3774 - acc: 0.8440 - val_loss: 0.3358 - val_acc: 0.8762\n",
            "Epoch 30/200\n",
            " - 0s - loss: 0.3764 - acc: 0.8428 - val_loss: 0.3371 - val_acc: 0.8750\n",
            "Epoch 31/200\n",
            " - 0s - loss: 0.3741 - acc: 0.8438 - val_loss: 0.3379 - val_acc: 0.8625\n",
            "Epoch 32/200\n",
            " - 0s - loss: 0.3724 - acc: 0.8447 - val_loss: 0.3383 - val_acc: 0.8625\n",
            "Epoch 33/200\n",
            " - 0s - loss: 0.3713 - acc: 0.8462 - val_loss: 0.3383 - val_acc: 0.8612\n",
            "Epoch 34/200\n",
            " - 0s - loss: 0.3776 - acc: 0.8390 - val_loss: 0.3384 - val_acc: 0.8625\n",
            "Epoch 35/200\n",
            " - 0s - loss: 0.3726 - acc: 0.8419 - val_loss: 0.3370 - val_acc: 0.8625\n",
            "Epoch 36/200\n",
            " - 0s - loss: 0.3722 - acc: 0.8422 - val_loss: 0.3357 - val_acc: 0.8662\n",
            "Epoch 37/200\n",
            " - 0s - loss: 0.3693 - acc: 0.8457 - val_loss: 0.3374 - val_acc: 0.8625\n",
            "Epoch 38/200\n",
            " - 0s - loss: 0.3715 - acc: 0.8458 - val_loss: 0.3372 - val_acc: 0.8612\n",
            "Epoch 39/200\n",
            " - 0s - loss: 0.3726 - acc: 0.8449 - val_loss: 0.3369 - val_acc: 0.8625\n",
            "Epoch 40/200\n",
            " - 0s - loss: 0.3722 - acc: 0.8458 - val_loss: 0.3364 - val_acc: 0.8625\n",
            "Epoch 41/200\n",
            " - 0s - loss: 0.3693 - acc: 0.8447 - val_loss: 0.3373 - val_acc: 0.8600\n",
            "Epoch 42/200\n",
            " - 0s - loss: 0.3689 - acc: 0.8461 - val_loss: 0.3369 - val_acc: 0.8638\n",
            "Epoch 43/200\n",
            " - 0s - loss: 0.3718 - acc: 0.8418 - val_loss: 0.3398 - val_acc: 0.8600\n",
            "Epoch 44/200\n",
            " - 0s - loss: 0.3754 - acc: 0.8433 - val_loss: 0.3385 - val_acc: 0.8612\n",
            "Epoch 45/200\n",
            " - 0s - loss: 0.3686 - acc: 0.8457 - val_loss: 0.3364 - val_acc: 0.8650\n",
            "Epoch 46/200\n",
            " - 0s - loss: 0.3719 - acc: 0.8471 - val_loss: 0.3376 - val_acc: 0.8612\n",
            "Epoch 47/200\n",
            " - 0s - loss: 0.3714 - acc: 0.8456 - val_loss: 0.3349 - val_acc: 0.8725\n",
            "Epoch 48/200\n",
            " - 0s - loss: 0.3662 - acc: 0.8450 - val_loss: 0.3384 - val_acc: 0.8612\n",
            "Epoch 49/200\n",
            " - 0s - loss: 0.3743 - acc: 0.8418 - val_loss: 0.3386 - val_acc: 0.8612\n",
            "Epoch 50/200\n",
            " - 0s - loss: 0.3758 - acc: 0.8443 - val_loss: 0.3413 - val_acc: 0.8575\n",
            "Epoch 51/200\n",
            " - 0s - loss: 0.3667 - acc: 0.8462 - val_loss: 0.3378 - val_acc: 0.8638\n",
            "Epoch 52/200\n",
            " - 0s - loss: 0.3708 - acc: 0.8474 - val_loss: 0.3388 - val_acc: 0.8625\n",
            "Epoch 53/200\n",
            " - 0s - loss: 0.3739 - acc: 0.8458 - val_loss: 0.3356 - val_acc: 0.8625\n",
            "Epoch 54/200\n",
            " - 0s - loss: 0.3725 - acc: 0.8468 - val_loss: 0.3364 - val_acc: 0.8638\n",
            "Epoch 55/200\n",
            " - 0s - loss: 0.3725 - acc: 0.8469 - val_loss: 0.3398 - val_acc: 0.8575\n",
            "Epoch 56/200\n",
            " - 0s - loss: 0.3667 - acc: 0.8462 - val_loss: 0.3358 - val_acc: 0.8625\n",
            "Epoch 57/200\n",
            " - 0s - loss: 0.3658 - acc: 0.8482 - val_loss: 0.3346 - val_acc: 0.8638\n",
            "Epoch 58/200\n",
            " - 0s - loss: 0.3684 - acc: 0.8486 - val_loss: 0.3365 - val_acc: 0.8650\n",
            "Epoch 59/200\n",
            " - 0s - loss: 0.3689 - acc: 0.8453 - val_loss: 0.3355 - val_acc: 0.8650\n",
            "Epoch 60/200\n",
            " - 0s - loss: 0.3661 - acc: 0.8456 - val_loss: 0.3350 - val_acc: 0.8662\n",
            "Epoch 61/200\n",
            " - 0s - loss: 0.3680 - acc: 0.8489 - val_loss: 0.3325 - val_acc: 0.8675\n",
            "Epoch 62/200\n",
            " - 0s - loss: 0.3675 - acc: 0.8501 - val_loss: 0.3342 - val_acc: 0.8712\n",
            "Epoch 63/200\n",
            " - 0s - loss: 0.3676 - acc: 0.8469 - val_loss: 0.3325 - val_acc: 0.8650\n",
            "Epoch 64/200\n",
            " - 0s - loss: 0.3680 - acc: 0.8468 - val_loss: 0.3312 - val_acc: 0.8675\n",
            "Epoch 65/200\n",
            " - 0s - loss: 0.3678 - acc: 0.8486 - val_loss: 0.3355 - val_acc: 0.8638\n",
            "Epoch 66/200\n",
            " - 0s - loss: 0.3709 - acc: 0.8442 - val_loss: 0.3340 - val_acc: 0.8650\n",
            "Epoch 67/200\n",
            " - 0s - loss: 0.3642 - acc: 0.8489 - val_loss: 0.3323 - val_acc: 0.8700\n",
            "Epoch 68/200\n",
            " - 0s - loss: 0.3658 - acc: 0.8500 - val_loss: 0.3352 - val_acc: 0.8675\n",
            "Epoch 69/200\n",
            " - 0s - loss: 0.3683 - acc: 0.8476 - val_loss: 0.3315 - val_acc: 0.8675\n",
            "Epoch 70/200\n",
            " - 0s - loss: 0.3661 - acc: 0.8464 - val_loss: 0.3337 - val_acc: 0.8675\n",
            "Epoch 71/200\n",
            " - 0s - loss: 0.3656 - acc: 0.8485 - val_loss: 0.3316 - val_acc: 0.8688\n",
            "Epoch 72/200\n",
            " - 0s - loss: 0.3621 - acc: 0.8504 - val_loss: 0.3325 - val_acc: 0.8688\n",
            "Epoch 73/200\n",
            " - 0s - loss: 0.3682 - acc: 0.8456 - val_loss: 0.3368 - val_acc: 0.8675\n",
            "Epoch 74/200\n",
            " - 0s - loss: 0.3678 - acc: 0.8482 - val_loss: 0.3347 - val_acc: 0.8638\n",
            "Epoch 75/200\n",
            " - 0s - loss: 0.3704 - acc: 0.8471 - val_loss: 0.3327 - val_acc: 0.8688\n",
            "Epoch 76/200\n",
            " - 0s - loss: 0.3648 - acc: 0.8501 - val_loss: 0.3337 - val_acc: 0.8662\n",
            "Epoch 77/200\n",
            " - 0s - loss: 0.3640 - acc: 0.8482 - val_loss: 0.3339 - val_acc: 0.8675\n",
            "Epoch 78/200\n",
            " - 0s - loss: 0.3690 - acc: 0.8461 - val_loss: 0.3315 - val_acc: 0.8688\n",
            "Epoch 79/200\n",
            " - 0s - loss: 0.3630 - acc: 0.8533 - val_loss: 0.3306 - val_acc: 0.8662\n",
            "Epoch 80/200\n",
            " - 0s - loss: 0.3654 - acc: 0.8472 - val_loss: 0.3316 - val_acc: 0.8662\n",
            "Epoch 81/200\n",
            " - 0s - loss: 0.3680 - acc: 0.8478 - val_loss: 0.3341 - val_acc: 0.8638\n",
            "Epoch 82/200\n",
            " - 0s - loss: 0.3624 - acc: 0.8507 - val_loss: 0.3347 - val_acc: 0.8600\n",
            "Epoch 83/200\n",
            " - 0s - loss: 0.3670 - acc: 0.8481 - val_loss: 0.3342 - val_acc: 0.8650\n",
            "Epoch 84/200\n",
            " - 0s - loss: 0.3579 - acc: 0.8542 - val_loss: 0.3322 - val_acc: 0.8650\n",
            "Epoch 85/200\n",
            " - 0s - loss: 0.3622 - acc: 0.8497 - val_loss: 0.3345 - val_acc: 0.8638\n",
            "Epoch 86/200\n",
            " - 0s - loss: 0.3622 - acc: 0.8476 - val_loss: 0.3314 - val_acc: 0.8650\n",
            "Epoch 87/200\n",
            " - 0s - loss: 0.3670 - acc: 0.8496 - val_loss: 0.3323 - val_acc: 0.8662\n",
            "Epoch 88/200\n",
            " - 0s - loss: 0.3660 - acc: 0.8457 - val_loss: 0.3337 - val_acc: 0.8638\n",
            "Epoch 89/200\n",
            " - 0s - loss: 0.3648 - acc: 0.8515 - val_loss: 0.3333 - val_acc: 0.8612\n",
            "Epoch 90/200\n",
            " - 0s - loss: 0.3653 - acc: 0.8496 - val_loss: 0.3339 - val_acc: 0.8638\n",
            "Epoch 91/200\n",
            " - 0s - loss: 0.3656 - acc: 0.8494 - val_loss: 0.3305 - val_acc: 0.8650\n",
            "Epoch 92/200\n",
            " - 0s - loss: 0.3660 - acc: 0.8471 - val_loss: 0.3302 - val_acc: 0.8650\n",
            "Epoch 93/200\n",
            " - 0s - loss: 0.3662 - acc: 0.8465 - val_loss: 0.3305 - val_acc: 0.8675\n",
            "Epoch 94/200\n",
            " - 0s - loss: 0.3631 - acc: 0.8503 - val_loss: 0.3327 - val_acc: 0.8612\n",
            "Epoch 95/200\n",
            " - 0s - loss: 0.3630 - acc: 0.8478 - val_loss: 0.3317 - val_acc: 0.8600\n",
            "Epoch 96/200\n",
            " - 0s - loss: 0.3667 - acc: 0.8489 - val_loss: 0.3321 - val_acc: 0.8625\n",
            "Epoch 97/200\n",
            " - 0s - loss: 0.3653 - acc: 0.8475 - val_loss: 0.3299 - val_acc: 0.8662\n",
            "Epoch 98/200\n",
            " - 0s - loss: 0.3671 - acc: 0.8479 - val_loss: 0.3317 - val_acc: 0.8588\n",
            "Epoch 99/200\n",
            " - 0s - loss: 0.3624 - acc: 0.8515 - val_loss: 0.3292 - val_acc: 0.8688\n",
            "Epoch 100/200\n",
            " - 0s - loss: 0.3658 - acc: 0.8485 - val_loss: 0.3293 - val_acc: 0.8712\n",
            "Epoch 101/200\n",
            " - 0s - loss: 0.3650 - acc: 0.8479 - val_loss: 0.3316 - val_acc: 0.8625\n",
            "Epoch 102/200\n",
            " - 0s - loss: 0.3657 - acc: 0.8494 - val_loss: 0.3291 - val_acc: 0.8662\n",
            "Epoch 103/200\n",
            " - 0s - loss: 0.3630 - acc: 0.8500 - val_loss: 0.3305 - val_acc: 0.8650\n",
            "Epoch 104/200\n",
            " - 0s - loss: 0.3643 - acc: 0.8476 - val_loss: 0.3319 - val_acc: 0.8625\n",
            "Epoch 105/200\n",
            " - 0s - loss: 0.3635 - acc: 0.8494 - val_loss: 0.3317 - val_acc: 0.8600\n",
            "Epoch 106/200\n",
            " - 0s - loss: 0.3634 - acc: 0.8478 - val_loss: 0.3278 - val_acc: 0.8662\n",
            "Epoch 107/200\n",
            " - 0s - loss: 0.3641 - acc: 0.8511 - val_loss: 0.3289 - val_acc: 0.8662\n",
            "Epoch 108/200\n",
            " - 0s - loss: 0.3648 - acc: 0.8493 - val_loss: 0.3297 - val_acc: 0.8675\n",
            "Epoch 109/200\n",
            " - 0s - loss: 0.3595 - acc: 0.8524 - val_loss: 0.3297 - val_acc: 0.8638\n",
            "Epoch 110/200\n",
            " - 0s - loss: 0.3596 - acc: 0.8508 - val_loss: 0.3291 - val_acc: 0.8612\n",
            "Epoch 111/200\n",
            " - 0s - loss: 0.3620 - acc: 0.8489 - val_loss: 0.3270 - val_acc: 0.8675\n",
            "Epoch 112/200\n",
            " - 0s - loss: 0.3579 - acc: 0.8497 - val_loss: 0.3317 - val_acc: 0.8638\n",
            "Epoch 113/200\n",
            " - 0s - loss: 0.3639 - acc: 0.8496 - val_loss: 0.3305 - val_acc: 0.8638\n",
            "Epoch 114/200\n",
            " - 0s - loss: 0.3644 - acc: 0.8500 - val_loss: 0.3317 - val_acc: 0.8625\n",
            "Epoch 115/200\n",
            " - 0s - loss: 0.3641 - acc: 0.8507 - val_loss: 0.3324 - val_acc: 0.8638\n",
            "Epoch 116/200\n",
            " - 0s - loss: 0.3637 - acc: 0.8472 - val_loss: 0.3331 - val_acc: 0.8638\n",
            "Epoch 117/200\n",
            " - 0s - loss: 0.3652 - acc: 0.8472 - val_loss: 0.3324 - val_acc: 0.8638\n",
            "Epoch 118/200\n",
            " - 0s - loss: 0.3636 - acc: 0.8483 - val_loss: 0.3321 - val_acc: 0.8638\n",
            "Epoch 119/200\n",
            " - 0s - loss: 0.3609 - acc: 0.8507 - val_loss: 0.3305 - val_acc: 0.8625\n",
            "Epoch 120/200\n",
            " - 0s - loss: 0.3617 - acc: 0.8504 - val_loss: 0.3299 - val_acc: 0.8650\n",
            "Epoch 121/200\n",
            " - 0s - loss: 0.3616 - acc: 0.8494 - val_loss: 0.3309 - val_acc: 0.8625\n",
            "Epoch 122/200\n",
            " - 0s - loss: 0.3645 - acc: 0.8475 - val_loss: 0.3321 - val_acc: 0.8625\n",
            "Epoch 123/200\n",
            " - 0s - loss: 0.3598 - acc: 0.8492 - val_loss: 0.3310 - val_acc: 0.8612\n",
            "Epoch 124/200\n",
            " - 0s - loss: 0.3649 - acc: 0.8492 - val_loss: 0.3304 - val_acc: 0.8638\n",
            "Epoch 125/200\n",
            " - 0s - loss: 0.3610 - acc: 0.8524 - val_loss: 0.3300 - val_acc: 0.8638\n",
            "Epoch 126/200\n",
            " - 0s - loss: 0.3639 - acc: 0.8508 - val_loss: 0.3318 - val_acc: 0.8612\n",
            "Epoch 127/200\n",
            " - 0s - loss: 0.3616 - acc: 0.8506 - val_loss: 0.3336 - val_acc: 0.8612\n",
            "Epoch 128/200\n",
            " - 0s - loss: 0.3619 - acc: 0.8529 - val_loss: 0.3317 - val_acc: 0.8625\n",
            "Epoch 129/200\n",
            " - 0s - loss: 0.3547 - acc: 0.8558 - val_loss: 0.3283 - val_acc: 0.8662\n",
            "Epoch 130/200\n",
            " - 0s - loss: 0.3609 - acc: 0.8540 - val_loss: 0.3289 - val_acc: 0.8638\n",
            "Epoch 131/200\n",
            " - 0s - loss: 0.3616 - acc: 0.8493 - val_loss: 0.3303 - val_acc: 0.8638\n",
            "Epoch 132/200\n",
            " - 0s - loss: 0.3648 - acc: 0.8496 - val_loss: 0.3308 - val_acc: 0.8625\n",
            "Epoch 133/200\n",
            " - 0s - loss: 0.3630 - acc: 0.8486 - val_loss: 0.3305 - val_acc: 0.8625\n",
            "Epoch 134/200\n",
            " - 0s - loss: 0.3690 - acc: 0.8489 - val_loss: 0.3332 - val_acc: 0.8625\n",
            "Epoch 135/200\n",
            " - 0s - loss: 0.3594 - acc: 0.8497 - val_loss: 0.3309 - val_acc: 0.8612\n",
            "Epoch 136/200\n",
            " - 0s - loss: 0.3599 - acc: 0.8507 - val_loss: 0.3332 - val_acc: 0.8600\n",
            "Epoch 137/200\n",
            " - 0s - loss: 0.3609 - acc: 0.8504 - val_loss: 0.3316 - val_acc: 0.8612\n",
            "Epoch 138/200\n",
            " - 0s - loss: 0.3613 - acc: 0.8508 - val_loss: 0.3325 - val_acc: 0.8600\n",
            "Epoch 139/200\n",
            " - 0s - loss: 0.3655 - acc: 0.8476 - val_loss: 0.3307 - val_acc: 0.8638\n",
            "Epoch 140/200\n",
            " - 0s - loss: 0.3600 - acc: 0.8500 - val_loss: 0.3312 - val_acc: 0.8588\n",
            "Epoch 141/200\n",
            " - 0s - loss: 0.3671 - acc: 0.8479 - val_loss: 0.3346 - val_acc: 0.8612\n",
            "Epoch 142/200\n",
            " - 0s - loss: 0.3645 - acc: 0.8492 - val_loss: 0.3316 - val_acc: 0.8612\n",
            "Epoch 143/200\n",
            " - 0s - loss: 0.3653 - acc: 0.8488 - val_loss: 0.3314 - val_acc: 0.8612\n",
            "Epoch 144/200\n",
            " - 0s - loss: 0.3624 - acc: 0.8501 - val_loss: 0.3294 - val_acc: 0.8650\n",
            "Epoch 145/200\n",
            " - 0s - loss: 0.3621 - acc: 0.8507 - val_loss: 0.3327 - val_acc: 0.8588\n",
            "Epoch 146/200\n",
            " - 0s - loss: 0.3614 - acc: 0.8512 - val_loss: 0.3303 - val_acc: 0.8638\n",
            "Epoch 147/200\n",
            " - 0s - loss: 0.3643 - acc: 0.8524 - val_loss: 0.3300 - val_acc: 0.8612\n",
            "Epoch 148/200\n",
            " - 0s - loss: 0.3615 - acc: 0.8511 - val_loss: 0.3329 - val_acc: 0.8600\n",
            "Epoch 149/200\n",
            " - 0s - loss: 0.3649 - acc: 0.8503 - val_loss: 0.3309 - val_acc: 0.8575\n",
            "Epoch 150/200\n",
            " - 0s - loss: 0.3589 - acc: 0.8550 - val_loss: 0.3294 - val_acc: 0.8612\n",
            "Epoch 151/200\n",
            " - 0s - loss: 0.3591 - acc: 0.8525 - val_loss: 0.3322 - val_acc: 0.8575\n",
            "Epoch 152/200\n",
            " - 0s - loss: 0.3651 - acc: 0.8476 - val_loss: 0.3328 - val_acc: 0.8562\n",
            "Epoch 153/200\n",
            " - 0s - loss: 0.3629 - acc: 0.8496 - val_loss: 0.3294 - val_acc: 0.8638\n",
            "Epoch 154/200\n",
            " - 0s - loss: 0.3620 - acc: 0.8515 - val_loss: 0.3288 - val_acc: 0.8625\n",
            "Epoch 155/200\n",
            " - 0s - loss: 0.3631 - acc: 0.8524 - val_loss: 0.3316 - val_acc: 0.8612\n",
            "Epoch 156/200\n",
            " - 0s - loss: 0.3555 - acc: 0.8522 - val_loss: 0.3317 - val_acc: 0.8588\n",
            "Epoch 157/200\n",
            " - 0s - loss: 0.3593 - acc: 0.8488 - val_loss: 0.3337 - val_acc: 0.8600\n",
            "Epoch 158/200\n",
            " - 0s - loss: 0.3667 - acc: 0.8497 - val_loss: 0.3294 - val_acc: 0.8588\n",
            "Epoch 159/200\n",
            " - 0s - loss: 0.3637 - acc: 0.8508 - val_loss: 0.3298 - val_acc: 0.8588\n",
            "Epoch 160/200\n",
            " - 0s - loss: 0.3626 - acc: 0.8512 - val_loss: 0.3291 - val_acc: 0.8612\n",
            "Epoch 161/200\n",
            " - 0s - loss: 0.3594 - acc: 0.8518 - val_loss: 0.3290 - val_acc: 0.8650\n",
            "Epoch 162/200\n",
            " - 0s - loss: 0.3636 - acc: 0.8497 - val_loss: 0.3320 - val_acc: 0.8600\n",
            "Epoch 163/200\n",
            " - 0s - loss: 0.3607 - acc: 0.8511 - val_loss: 0.3307 - val_acc: 0.8625\n",
            "Epoch 164/200\n",
            " - 0s - loss: 0.3612 - acc: 0.8483 - val_loss: 0.3294 - val_acc: 0.8625\n",
            "Epoch 165/200\n",
            " - 0s - loss: 0.3576 - acc: 0.8514 - val_loss: 0.3265 - val_acc: 0.8675\n",
            "Epoch 166/200\n",
            " - 0s - loss: 0.3629 - acc: 0.8496 - val_loss: 0.3296 - val_acc: 0.8650\n",
            "Epoch 167/200\n",
            " - 0s - loss: 0.3622 - acc: 0.8550 - val_loss: 0.3287 - val_acc: 0.8688\n",
            "Epoch 168/200\n",
            " - 0s - loss: 0.3612 - acc: 0.8476 - val_loss: 0.3376 - val_acc: 0.8612\n",
            "Epoch 169/200\n",
            " - 0s - loss: 0.3671 - acc: 0.8478 - val_loss: 0.3346 - val_acc: 0.8600\n",
            "Epoch 170/200\n",
            " - 0s - loss: 0.3564 - acc: 0.8539 - val_loss: 0.3305 - val_acc: 0.8638\n",
            "Epoch 171/200\n",
            " - 0s - loss: 0.3630 - acc: 0.8483 - val_loss: 0.3346 - val_acc: 0.8588\n",
            "Epoch 172/200\n",
            " - 0s - loss: 0.3625 - acc: 0.8460 - val_loss: 0.3346 - val_acc: 0.8588\n",
            "Epoch 173/200\n",
            " - 0s - loss: 0.3616 - acc: 0.8467 - val_loss: 0.3331 - val_acc: 0.8612\n",
            "Epoch 174/200\n",
            " - 0s - loss: 0.3627 - acc: 0.8500 - val_loss: 0.3303 - val_acc: 0.8600\n",
            "Epoch 175/200\n",
            " - 0s - loss: 0.3612 - acc: 0.8504 - val_loss: 0.3352 - val_acc: 0.8588\n",
            "Epoch 176/200\n",
            " - 0s - loss: 0.3610 - acc: 0.8517 - val_loss: 0.3306 - val_acc: 0.8625\n",
            "Epoch 177/200\n",
            " - 0s - loss: 0.3605 - acc: 0.8508 - val_loss: 0.3325 - val_acc: 0.8588\n",
            "Epoch 178/200\n",
            " - 0s - loss: 0.3591 - acc: 0.8510 - val_loss: 0.3299 - val_acc: 0.8662\n",
            "Epoch 179/200\n",
            " - 0s - loss: 0.3596 - acc: 0.8524 - val_loss: 0.3311 - val_acc: 0.8650\n",
            "Epoch 180/200\n",
            " - 0s - loss: 0.3656 - acc: 0.8494 - val_loss: 0.3302 - val_acc: 0.8600\n",
            "Epoch 181/200\n",
            " - 0s - loss: 0.3551 - acc: 0.8521 - val_loss: 0.3301 - val_acc: 0.8612\n",
            "Epoch 182/200\n",
            " - 0s - loss: 0.3625 - acc: 0.8489 - val_loss: 0.3330 - val_acc: 0.8625\n",
            "Epoch 183/200\n",
            " - 0s - loss: 0.3603 - acc: 0.8511 - val_loss: 0.3292 - val_acc: 0.8650\n",
            "Epoch 184/200\n",
            " - 0s - loss: 0.3642 - acc: 0.8489 - val_loss: 0.3329 - val_acc: 0.8600\n",
            "Epoch 185/200\n",
            " - 0s - loss: 0.3606 - acc: 0.8514 - val_loss: 0.3284 - val_acc: 0.8638\n",
            "Epoch 186/200\n",
            " - 0s - loss: 0.3586 - acc: 0.8517 - val_loss: 0.3291 - val_acc: 0.8625\n",
            "Epoch 187/200\n",
            " - 0s - loss: 0.3599 - acc: 0.8510 - val_loss: 0.3317 - val_acc: 0.8600\n",
            "Epoch 188/200\n",
            " - 0s - loss: 0.3612 - acc: 0.8515 - val_loss: 0.3300 - val_acc: 0.8625\n",
            "Epoch 189/200\n",
            " - 0s - loss: 0.3572 - acc: 0.8522 - val_loss: 0.3338 - val_acc: 0.8588\n",
            "Epoch 190/200\n",
            " - 0s - loss: 0.3564 - acc: 0.8533 - val_loss: 0.3306 - val_acc: 0.8638\n",
            "Epoch 191/200\n",
            " - 0s - loss: 0.3610 - acc: 0.8529 - val_loss: 0.3316 - val_acc: 0.8625\n",
            "Epoch 192/200\n",
            " - 0s - loss: 0.3604 - acc: 0.8508 - val_loss: 0.3328 - val_acc: 0.8600\n",
            "Epoch 193/200\n",
            " - 0s - loss: 0.3615 - acc: 0.8533 - val_loss: 0.3345 - val_acc: 0.8600\n",
            "Epoch 194/200\n",
            " - 0s - loss: 0.3588 - acc: 0.8528 - val_loss: 0.3334 - val_acc: 0.8612\n",
            "Epoch 195/200\n",
            " - 0s - loss: 0.3614 - acc: 0.8510 - val_loss: 0.3282 - val_acc: 0.8650\n",
            "Epoch 196/200\n",
            " - 0s - loss: 0.3629 - acc: 0.8524 - val_loss: 0.3307 - val_acc: 0.8625\n",
            "Epoch 197/200\n",
            " - 0s - loss: 0.3611 - acc: 0.8515 - val_loss: 0.3287 - val_acc: 0.8612\n",
            "Epoch 198/200\n",
            " - 0s - loss: 0.3598 - acc: 0.8507 - val_loss: 0.3293 - val_acc: 0.8625\n",
            "Epoch 199/200\n",
            " - 0s - loss: 0.3572 - acc: 0.8515 - val_loss: 0.3334 - val_acc: 0.8600\n",
            "Epoch 200/200\n",
            " - 0s - loss: 0.3609 - acc: 0.8510 - val_loss: 0.3320 - val_acc: 0.8588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G298V9J0-QIm",
        "colab_type": "text"
      },
      "source": [
        "The breakdown of the inputs for compiling is as follows:\n",
        "\n",
        "* X_train The independent variable portion of the data which needs to be fitted with the model.\n",
        "\n",
        "* Y_train The output portion of the data which the model needs to produce after fitting.\n",
        "\n",
        "* batch_size: How often we want to back-propogate the error values so that individual node weights can be adjusted.\n",
        "\n",
        "* epochs: The number of times we want to run the entire test data over again to tune the weights. This is like the fuel of the algorithm.\n",
        "\n",
        "* validation_split: 0.2 The fraction of data to use for validation data.\n",
        "\n",
        "The output network should converge to an accuracy of around 85%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPnnAfBD-r-B",
        "colab_type": "text"
      },
      "source": [
        "**Testing the NN **-  *Predicting the Test set results*\n",
        "\n",
        "This shows the probability of a customer leaving given the testing data. \n",
        "\n",
        "Each row in X_test corresponds to a row in Y_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg73xnCr9b2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "1cf02a5f-4950-45ad-cec3-12b5fda1c26e"
      },
      "source": [
        "plt.plot(np.array(history.history['acc']) * 100)\n",
        "plt.plot(np.array(history.history['val_acc']) * 100)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.title('Accuracy over epochs')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEcCAYAAAAoSqjDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQiNFQQghhOb/Aa6RIy7oNX65AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZlYkwiz_BON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e0375f72-dea4-4198-e6dd-f7ba305c8a6c"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(y_pred[:5])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.25294662]\n",
            " [0.298243  ]\n",
            " [0.24798924]\n",
            " [0.07395825]\n",
            " [0.06605911]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ixRrpC8_PHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bbe44803-275c-49be-8d12-6f50045fe54f"
      },
      "source": [
        "##Predict the results using 0.5 as a threshold.\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "print(y_pred[:5])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5e3TNh2_TxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b7b2954f-1862-4d4e-a2a4-159fe8189dc8"
      },
      "source": [
        "##Printing the accuracy score and the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confmatrix = confusion_matrix(y_test, y_pred)\n",
        "print(confmatrix)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1550   45]\n",
            " [ 235  170]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4nSODQz_jSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "511e41ea-bd88-4dd1-f069-a0e9a98e1f2a"
      },
      "source": [
        "print (((confmatrix[0][0]+confmatrix[1][1])*100)/(len(y_test)), '% of test data where customers leaving the bank are classified accurately')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86.0 % of test data where customers leaving the bank are classified accurately\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbjUJstX_66t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}